# Ethics & Accessibility Reflection

## 1. What are the main ethical risks of this project?
- **Bias in Models**: ML forecasts may reflect existing biases in housing data (e.g., regional underrepresentation, discriminatory lending history).
- **Misinformation**: LLM-generated summaries could hallucinate or oversimplify, leading to poor decision-making.
- **Overreliance on AI**: Stakeholders may trust AI outputs without verifying the data or considering limitations.

---

## 2. How will you mitigate these risks?
- **Bias Checks**: Regularly audit training datasets for bias and test models across diverse regions.
- **Transparency**: Include disclaimers clarifying that forecasts are probabilistic, not guarantees.
- **Human Oversight**: Encourage policymakers and investors to use outputs alongside expert judgment, not as a substitute.

---

## 3. How does your project ensure accessibility?
- **Plain Language Summaries**: Use LLMs to generate simplified, clear narratives understandable by non-specialists.
- **Interactive Dashboard**: Design with WCAG (Web Content Accessibility Guidelines) in mindâ€”contrasts, alt text, keyboard navigation.
- **Inclusive Design**: Provide multiple formats (charts, text, downloadable reports) to support diverse user needs.

---

## 4. What standards or guidelines will you follow?
- **WCAG 2.1** for accessibility compliance.
- **Fair Housing Act principles** to avoid reinforcing housing inequality.
- **NIST AI Risk Management Framework (AI RMF)** for responsible AI development.

---

## 5. Reflection
This project aims to make complex housing market insights **more transparent, accessible, and equitable**. By combining ML and LLMs with strong ethical safeguards, it reduces barriers to information while protecting against bias, misinformation, and exclusion.
